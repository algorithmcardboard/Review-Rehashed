\documentclass{article}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{systeme}
\usepackage{graphicx}
\graphicspath{ {images/} }
\usepackage{amssymb}
\usepackage{listings}
\usepackage[dvipsone,pdfpagelabels=false]{hyperref}
\usepackage[T1]{fontenc}
\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{Himaja Rachakonda, Anirudhan J. Rajagopalan}

\begin{document}

\title{Web Search Engines --- Reviews-Rehashed}
\date{March 21, 2016}
\author{Himaja Rachakonda, Anirudhan J. Rajagopalan\\ N14633788, N18824115\\ hr970, ajr619}
\maketitle
\newpage

\section{Objective}
The aim of "Reviews-Rehashed" is to build a specialized search engine to search product reviews pertaining to a product and its features. The search queries are in theform of <product,feature> tuples. This search engine will crawl reviews from various e-commerce websites such as Amazon and Best-Buy.com to fetch reviews data of various products. It searches for the user query and presents the links to the results after ranking the documents based on the intrinsic quality of the document as well asthe retrieval score. The quality of the document is based on a static score derived from the features of a review like the ratings, review-date, comments etc. We have implemented the search engine for electronics - mobiles data from Amazon.com. There is a huge scope of expanding this to other products and other domains as well.

\section{Data Sources}
Amazon.com and BestBuy.com were the options considered to collect information regarding products and their reviews. To build a crawler to fetch the data, a preliminarystudy was conducted on the following to understand the website page layout and structure ---

\begin{enumerate}
	\item[1. ] User behaviour to search for a particular product and review.
	\item[2. ] Patterns in the URLs of the websites to reach to a particular product / product category / review / etc.
	\item[3. ] Examining the sitemap.xml of Amazon.com and BestBuy.com to get all the URLs of the domain.
\end{enumerate} 

Sitemap is a list of pages of a web site accessible to crawlers or users. It can be either a document in any form used as a planning tool for Web design, or a Web pagethat lists the pages on a Web site, typically organized in hierarchical fashion. Sitemaps make relationships between pages and other content components. It shows shapeof information space in overview. Sitemaps can demonstrate organization, navigation, and labeling system.

Sitemaps are a useful tool for making sites built in Flash and other non-html languages searchable. If a website's navigation is built with Flash, an automated search program would probably only find the initial homepage; subsequent pages are unlikely to be found without an XML sitemap.

This helped us to make sure all the review pages are searchable by our search-engine and also to find useful patterns which help in identifying each product and reviewwithin each of the domains of Amazon and BestBuy. Because of the vast expense of the data and the crawling required to be done, we have restricted our project to Amazon Review Data pertaining to Mobile Phones under Electronics Sections. This can be scaled easily to other categories and domains seamlessly with appropriate crawler jobs. 

All the review pages of a particular product with an ASIN Id can be found at a URL in the following format -

\begin{center}
\label{sec:urlPattern}
	www.amazon.com/<Anything>/product-reviews/<ASIN>/
\end{center}

Every Review of a product has a unique Review ID, and therefore each review can be accessed by a URL in the following format - 
\begin{center}
	http://www.amazon.com/gp/customer-reviews/<Review-ID>/
\end{center}

\section{Data Collection}

Data Collection was executed in two phases - 

\begin{description}
	\item[Amazon Product Crawler: ] Fetches all the unique Ids for all mobile phone products from Amazon.com. This is required to construct the seedUrls for each product as mentioned above in the \hyperref[sec:dataSources] Data Sources Section.
	\item[Reviews Crawler: ] This crawler take the output of the the Amazon Product Crawler as the input to construct a seed Url for each product Id. All the unique IDs (ASINs) are stored, which are used to fetch Reviews from each product. These reviews can be accessed from this page through the links in the pagination bar. Eachpage consists of 10 reviews and the crawler goes to the depth until which there are no more review pages to be crawled for that product. Therefore, this product level URL is given as a seedURL for every product to crawl across various review pages through the links in the pagination bar.
\end{description}

The data has been collected for around 500 produts with a total of 150000 reviews. The following data about each review is collected as indexable fields based on whichthe review will be scored during the search time --

\begin{description}
	\item[1. ] Review Content
	\item[2. ] Review Title
	\item[3. ] Review Date
	\item[4. ] Number of Comments to the review
	\item[5. ] Number of people found this review helpful
	\item[6. ] Number of images posted by the user in this review
	\item[7. ] Ratings of the review 
	\item[8. ] Is the product a Verified Purchase
	\item[9. ] Review Length
	\item[10. ] Review Id
	\item[11. ] ASIN (Product Id)
\end{description}

\section{Search Engine Architecture}
\begin{figure}[h]
\includegraphics[natwidth=610,natheight=642]{reviewsRehashedArchitecture.png}
\end{figure}

The collected reviews data is indexed by the Indexer component and is stored in the index store. We have used Apache Lucene.

The Product related information from Amazon.com is retrieved by using the Amazon Product Advertising API. This API was used to fetch all the ASINs (Amazon Standard Identification Number) which uniquely identify a product by a given Id. These were fetched by the Amazon Product Information crawler job. We used these unique Ids of the product to crawl the reviews page-by-page using the Reviews Crawler providing a seed url constructed by including the ASINs.Depending on the computational complexity and performance of the search engines, we will try to expand the search feature to multiple features and combination of features.

The search engine will be built by using the following different components.
\begin{description}
  \item[Document Scoring : ]
  \item[Retriever Service : ]
  \item[Web interface:] A web interface for the user to issue the search queries.  This will be an interface with two text boxes. One for the product name and another for the feature name.
  \item[Index store:]  This is a Lucene index store, an inverted index, which maintains all indexable data required while retrieving search results.  The data will be populated and updated periodically by a crawler job that looks for updates to the data.  The data will be stored in lucene after preprocessing.
  \item[Amazon Crawler:] Given a set of seed urls for products, maximum depth of search and maximum number of pages to fetch, the crawler job fetches review data and dumps the data into a file location.
  \item[Preprocessing module:]  This module takes care of preprocessing the data as required by the NLP module and dumps the processed data into Lucene.
  \begin{description}
	 \item[Amazon WebCrawler : ] 
	 \item[Reviews WebCrawler : ]
  \end{description}
  \item[NLP module:] This module will be invoked during the query time.  This is essentially a machine learning model that was pre trained using the data collected by the crawler.  We use this to rank and get the list of all matching sentences for a given query.
\end{description}

\section{Document scoring}


\end{document}
